"""
X API v2 é‹ç”¨åˆ†æãƒ„ãƒ¼ãƒ«
AI Narrative Studio & GETHNOTE å‘ã‘

å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒª:
pip install tweepy pandas matplotlib seaborn python-dotenv
"""

import os
from datetime import datetime, timedelta
from typing import List, Dict, Optional
import tweepy
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from dotenv import load_dotenv

# æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆè¨­å®šï¼ˆWindowsç’°å¢ƒï¼‰
plt.rcParams['font.sans-serif'] = ['MS Gothic']
plt.rcParams['axes.unicode_minus'] = False


class XAnalyzer:
    """X API v2ã‚’ä½¿ã£ãŸé‹ç”¨åˆ†æã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, bearer_token: str):
        """
        åˆæœŸåŒ–
        
        Args:
            bearer_token: X API v2 Bearer Token
        """
        self.client = tweepy.Client(bearer_token=bearer_token)
        self.data_cache = []
        
    def fetch_user_tweets(
        self, 
        username: str, 
        max_results: int = 100,
        start_time: Optional[datetime] = None
    ) -> pd.DataFrame:
        """
        æŒ‡å®šãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æŠ•ç¨¿ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
        
        Args:
            username: Xã®ãƒ¦ãƒ¼ã‚¶ãƒ¼åï¼ˆ@ãªã—ï¼‰
            max_results: å–å¾—ã™ã‚‹æŠ•ç¨¿æ•°ï¼ˆæœ€å¤§100ä»¶/ãƒªã‚¯ã‚¨ã‚¹ãƒˆï¼‰
            start_time: å–å¾—é–‹å§‹æ—¥æ™‚ï¼ˆNoneã®å ´åˆã¯éå»30æ—¥ï¼‰
            
        Returns:
            æŠ•ç¨¿ãƒ‡ãƒ¼ã‚¿ã®DataFrame
        """
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼IDå–å¾—
        user = self.client.get_user(username=username)
        if not user.data:
            raise ValueError(f"ãƒ¦ãƒ¼ã‚¶ãƒ¼ {username} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        
        user_id = user.data.id
        
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯éå»30æ—¥
        if start_time is None:
            start_time = datetime.utcnow() - timedelta(days=30)
        
        # æŠ•ç¨¿å–å¾—
        tweets = self.client.get_users_tweets(
            id=user_id,
            max_results=max_results,
            start_time=start_time,
            tweet_fields=[
                'created_at', 'public_metrics', 'entities', 
                'attachments', 'referenced_tweets'
            ],
            expansions=['attachments.media_keys'],
            media_fields=['type', 'duration_ms', 'public_metrics']
        )
        
        if not tweets.data:
            return pd.DataFrame()
        
        # DataFrameã«å¤‰æ›
        records = []
        for tweet in tweets.data:
            record = {
                'tweet_id': tweet.id,
                'created_at': tweet.created_at,
                'text': tweet.text,
                'like_count': tweet.public_metrics['like_count'],
                'retweet_count': tweet.public_metrics['retweet_count'],
                'reply_count': tweet.public_metrics['reply_count'],
                'quote_count': tweet.public_metrics['quote_count'],
                'impression_count': tweet.public_metrics.get('impression_count', 0),
            }
            
            # ãƒ¡ãƒ‡ã‚£ã‚¢ç¨®åˆ¥åˆ¤å®š
            if hasattr(tweet, 'attachments') and tweet.attachments:
                media_keys = tweet.attachments.get('media_keys', [])
                if media_keys and tweets.includes and 'media' in tweets.includes:
                    media_types = [m.type for m in tweets.includes['media'] if m.media_key in media_keys]
                    record['media_type'] = media_types[0] if media_types else 'none'
                else:
                    record['media_type'] = 'none'
            else:
                record['media_type'] = 'none'
            
            # ã‚¹ãƒ¬ãƒƒãƒ‰åˆ¤å®šï¼ˆè¿”ä¿¡ãƒ„ã‚¤ãƒ¼ãƒˆã‹ã©ã†ã‹ï¼‰
            if hasattr(tweet, 'referenced_tweets') and tweet.referenced_tweets:
                is_reply = any(ref.type == 'replied_to' for ref in tweet.referenced_tweets)
                record['is_thread'] = is_reply
            else:
                record['is_thread'] = False
            
            records.append(record)
        
        df = pd.DataFrame(records)
        
        # è¿½åŠ ã®è¨ˆç®—ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰
        df['engagement_total'] = (
            df['like_count'] + 
            df['retweet_count'] + 
            df['reply_count'] + 
            df['quote_count']  # å¼•ç”¨RTã‚’è¿½åŠ 
        )
        df['posting_hour'] = df['created_at'].dt.hour
        df['posting_day'] = df['created_at'].dt.day_name()
        df['rt_like_ratio'] = df['retweet_count'] / (df['like_count'] + 1)  # ã‚¼ãƒ­é™¤ç®—å›é¿
        
        return df
    
    def calculate_engagement_rate(
        self, 
        df: pd.DataFrame, 
        follower_count: int
    ) -> pd.DataFrame:
        """
        ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆç‡ã‚’è¨ˆç®—
        
        Args:
            df: æŠ•ç¨¿ãƒ‡ãƒ¼ã‚¿ã®DataFrame
            follower_count: ãƒ•ã‚©ãƒ­ãƒ¯ãƒ¼æ•°
            
        Returns:
            ERåˆ—ãŒè¿½åŠ ã•ã‚ŒãŸDataFrame
        """
        df = df.copy()
        df['engagement_rate'] = (df['engagement_total'] / follower_count) * 100
        return df
    
    def analyze_by_media_type(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        ãƒ¡ãƒ‡ã‚£ã‚¢ç¨®åˆ¥ã”ã¨ã®åˆ†æ
        
        Args:
            df: æŠ•ç¨¿ãƒ‡ãƒ¼ã‚¿ã®DataFrame
            
        Returns:
            é›†è¨ˆçµæœã®DataFrame
        """
        summary = df.groupby('media_type').agg({
            'tweet_id': 'count',
            'like_count': 'mean',
            'retweet_count': 'mean',
            'reply_count': 'mean',
            'engagement_rate': 'mean',
            'rt_like_ratio': 'mean'
        }).round(2)
        
        summary.columns = ['æŠ•ç¨¿æ•°', 'å¹³å‡ã„ã„ã­', 'å¹³å‡RT', 'å¹³å‡è¿”ä¿¡', 'å¹³å‡ER(%)', 'RT/ã„ã„ã­æ¯”']
        return summary.sort_values('å¹³å‡ER(%)', ascending=False)
    
    def analyze_by_time(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        æ™‚é–“å¸¯åˆ¥ã®åˆ†æ
        
        Args:
            df: æŠ•ç¨¿ãƒ‡ãƒ¼ã‚¿ã®DataFrame
            
        Returns:
            æ™‚é–“å¸¯åˆ¥é›†è¨ˆçµæœã®DataFrame
        """
        # æ™‚é–“å¸¯ã‚’3æ™‚é–“åŒºåˆ‡ã‚Šã§åˆ†é¡
        df = df.copy()
        df['time_slot'] = pd.cut(
            df['posting_hour'], 
            bins=[0, 6, 9, 12, 15, 18, 21, 24],
            labels=['æ·±å¤œ(0-6)', 'æœ(6-9)', 'åˆå‰(9-12)', 'æ˜¼(12-15)', 'å¤•æ–¹(15-18)', 'å¤œ(18-21)', 'æ·±å¤œ(21-24)'],
            include_lowest=True
        )
        
        summary = df.groupby('time_slot').agg({
            'tweet_id': 'count',
            'engagement_rate': 'mean',
            'like_count': 'mean',
            'retweet_count': 'mean'
        }).round(2)
        
        summary.columns = ['æŠ•ç¨¿æ•°', 'å¹³å‡ER(%)', 'å¹³å‡ã„ã„ã­', 'å¹³å‡RT']
        return summary
    
    def create_heatmap(
        self, 
        df: pd.DataFrame, 
        metric: str = 'engagement_rate',
        output_path: Optional[str] = None
    ):
        """
        æ™‚é–“å¸¯Ã—æ›œæ—¥ã®ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ä½œæˆ
        
        Args:
            df: æŠ•ç¨¿ãƒ‡ãƒ¼ã‚¿ã®DataFrame
            metric: å¯è¦–åŒ–ã™ã‚‹æŒ‡æ¨™ï¼ˆ'engagement_rate', 'like_count'ãªã©ï¼‰
            output_path: ä¿å­˜å…ˆãƒ‘ã‚¹ï¼ˆNoneã®å ´åˆã¯è¡¨ç¤ºã®ã¿ï¼‰
        """
        # æ™‚é–“å¸¯åŒºåˆ†
        df = df.copy()
        df['time_slot'] = pd.cut(
            df['posting_hour'], 
            bins=[0, 6, 9, 12, 15, 18, 21, 24],
            labels=['0-6', '6-9', '9-12', '12-15', '15-18', '18-21', '21-24'],
            include_lowest=True
        )
        
        # ãƒ”ãƒœãƒƒãƒˆãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆ
        pivot = df.pivot_table(
            values=metric,
            index='time_slot',
            columns='posting_day',
            aggfunc='mean'
        )
        
        # æ›œæ—¥é †ã‚’èª¿æ•´
        day_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']
        pivot = pivot.reindex(columns=[d for d in day_order if d in pivot.columns])
        
        # ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—æç”»
        plt.figure(figsize=(12, 6))
        sns.heatmap(
            pivot, 
            annot=True, 
            fmt='.2f', 
            cmap='YlOrRd',
            cbar_kws={'label': metric}
        )
        plt.title(f'{metric} ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ï¼ˆæ™‚é–“å¸¯ Ã— æ›œæ—¥ï¼‰')
        plt.xlabel('æ›œæ—¥')
        plt.ylabel('æ™‚é–“å¸¯')
        plt.tight_layout()
        
        if output_path:
            plt.savefig(output_path, dpi=300, bbox_inches='tight')
        else:
            plt.show()
    
    def get_top_tweets(
        self, 
        df: pd.DataFrame, 
        metric: str = 'engagement_rate',
        top_n: int = 10
    ) -> pd.DataFrame:
        """
        é«˜ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æŠ•ç¨¿ã®æŠ½å‡º
        
        Args:
            df: æŠ•ç¨¿ãƒ‡ãƒ¼ã‚¿ã®DataFrame
            metric: ãƒ©ãƒ³ã‚­ãƒ³ã‚°åŸºæº–ã®æŒ‡æ¨™
            top_n: ä¸Šä½ä½•ä»¶å–å¾—ã™ã‚‹ã‹
            
        Returns:
            ä¸Šä½æŠ•ç¨¿ã®DataFrame
        """
        return df.nlargest(top_n, metric)[
            ['created_at', 'text', metric, 'like_count', 'retweet_count', 'media_type']
        ]
    
    def generate_monthly_report(
        self,
        df: pd.DataFrame,
        account_name: str,
        follower_count: int,
        output_dir: str = './reports'
    ):
        """
        æœˆæ¬¡ãƒ¬ãƒãƒ¼ãƒˆè‡ªå‹•ç”Ÿæˆ
        
        Args:
            df: æŠ•ç¨¿ãƒ‡ãƒ¼ã‚¿ã®DataFrame
            account_name: ã‚¢ã‚«ã‚¦ãƒ³ãƒˆå
            follower_count: ãƒ•ã‚©ãƒ­ãƒ¯ãƒ¼æ•°
            output_dir: ãƒ¬ãƒãƒ¼ãƒˆå‡ºåŠ›å…ˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        """
        os.makedirs(output_dir, exist_ok=True)
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        
        # 1. ã‚µãƒãƒªãƒ¼çµ±è¨ˆ
        summary = {
            'ã‚¢ã‚«ã‚¦ãƒ³ãƒˆ': account_name,
            'åˆ†ææœŸé–“': f"{df['created_at'].min()} ã€œ {df['created_at'].max()}",
            'ç·æŠ•ç¨¿æ•°': len(df),
            'ãƒ•ã‚©ãƒ­ãƒ¯ãƒ¼æ•°': follower_count,
            'å¹³å‡ER(%)': df['engagement_rate'].mean(),
            'ç·ã„ã„ã­æ•°': df['like_count'].sum(),
            'ç·RTæ•°': df['retweet_count'].sum(),
            'ç·è¿”ä¿¡æ•°': df['reply_count'].sum()
        }
        
        summary_df = pd.DataFrame([summary]).T
        summary_df.to_csv(f'{output_dir}/{timestamp}_{account_name}_summary.csv', encoding='utf-8-sig')
        
        # 2. ãƒ¡ãƒ‡ã‚£ã‚¢åˆ¥åˆ†æ
        media_analysis = self.analyze_by_media_type(df)
        media_analysis.to_csv(f'{output_dir}/{timestamp}_{account_name}_media_analysis.csv', encoding='utf-8-sig')
        
        # 3. æ™‚é–“å¸¯åˆ¥åˆ†æ
        time_analysis = self.analyze_by_time(df)
        time_analysis.to_csv(f'{output_dir}/{timestamp}_{account_name}_time_analysis.csv', encoding='utf-8-sig')
        
        # 4. ãƒˆãƒƒãƒ—10æŠ•ç¨¿
        top_tweets = self.get_top_tweets(df, 'engagement_rate', 10)
        top_tweets.to_csv(f'{output_dir}/{timestamp}_{account_name}_top_tweets.csv', encoding='utf-8-sig', index=False)
        
        # 5. ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—
        self.create_heatmap(
            df, 
            'engagement_rate',
            f'{output_dir}/{timestamp}_{account_name}_heatmap.png'
        )
        
        print(f"âœ… ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆå®Œäº†: {output_dir}/")
        return summary


# ä½¿ç”¨ä¾‹
if __name__ == '__main__':
    # ç’°å¢ƒå¤‰æ•°ã‹ã‚‰èªè¨¼æƒ…å ±èª­ã¿è¾¼ã¿
    load_dotenv()
    BEARER_TOKEN = os.getenv('X_BEARER_TOKEN')
    
    if not BEARER_TOKEN:
        print("ã‚¨ãƒ©ãƒ¼: .envãƒ•ã‚¡ã‚¤ãƒ«ã« X_BEARER_TOKEN ã‚’è¨­å®šã—ã¦ãã ã•ã„")
        exit(1)
    
    # ã‚¢ãƒŠãƒ©ã‚¤ã‚¶ãƒ¼åˆæœŸåŒ–
    analyzer = XAnalyzer(BEARER_TOKEN)
    
    # ç’°å¢ƒå¤‰æ•°ã‹ã‚‰ã‚¢ã‚«ã‚¦ãƒ³ãƒˆæƒ…å ±å–å¾—
    ai_narrative_username = os.getenv(
        'X_USERNAME_AI_NARRATIVE', 'ai_narrative25'
    )
    gethinu_username = os.getenv('X_USERNAME_GETHINU', 'gethinu')
    ai_narrative_followers = int(
        os.getenv('X_FOLLOWERS_AI_NARRATIVE', '500')
    )
    gethinu_followers = int(os.getenv('X_FOLLOWERS_GETHINU', '200'))
    
    # === AI Narrative Studio ã®åˆ†æä¾‹ ===
    print("ğŸ“Š AI Narrative Studio ã®åˆ†æã‚’é–‹å§‹...")
    try:
        # æŠ•ç¨¿ãƒ‡ãƒ¼ã‚¿å–å¾—ï¼ˆéå»30æ—¥ã€æœ€å¤§100ä»¶ï¼‰
        ai_narrative_df = analyzer.fetch_user_tweets(
            username=ai_narrative_username,
            max_results=100
        )
        
        # ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆç‡è¨ˆç®—
        ai_narrative_df = analyzer.calculate_engagement_rate(
            ai_narrative_df, ai_narrative_followers
        )
        
        # æœˆæ¬¡ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
        analyzer.generate_monthly_report(
            df=ai_narrative_df,
            account_name='AI_Narrative_Studio',
            follower_count=ai_narrative_followers
        )
        
        print("\nã€ãƒ¡ãƒ‡ã‚£ã‚¢åˆ¥åˆ†æã€‘")
        print(analyzer.analyze_by_media_type(ai_narrative_df))
        
        print("\nã€æ™‚é–“å¸¯åˆ¥åˆ†æã€‘")
        print(analyzer.analyze_by_time(ai_narrative_df))
        
    except Exception as e:
        print(f"ã‚¨ãƒ©ãƒ¼: {e}")
    
    # === GETHNOTE ã®åˆ†æä¾‹ ===
    print("\n\nğŸ“Š GETHNOTE ã®åˆ†æã‚’é–‹å§‹...")
    try:
        gethnote_df = analyzer.fetch_user_tweets(
            username=gethinu_username,
            max_results=100
        )
        
        gethnote_df = analyzer.calculate_engagement_rate(
            gethnote_df, gethinu_followers
        )
        
        analyzer.generate_monthly_report(
            df=gethnote_df,
            account_name='GETHNOTE',
            follower_count=gethinu_followers
        )
        
        print("\nã€ãƒˆãƒƒãƒ—10æŠ•ç¨¿ã€‘")
        print(analyzer.get_top_tweets(gethnote_df, 'engagement_rate', 10))
        
    except Exception as e:
        print(f"ã‚¨ãƒ©ãƒ¼: {e}")
