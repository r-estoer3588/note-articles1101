import csv
from pathlib import Path


def split_buffer_csv(input_file, posts_per_file=10):
    """Buffer CSVã‚’æŒ‡å®šã•ã‚ŒãŸæŠ•ç¨¿æ•°ã”ã¨ã«åˆ†å‰²"""
    input_path = Path(input_file)
    output_dir = input_path.parent / "buffer_split"
    output_dir.mkdir(exist_ok=True)
    
    # å…ƒã®ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰é€±æƒ…å ±ã‚’å–å¾—
    week_label = input_path.stem.replace("_buffer_import", "")
    
    # CSVã‚’èª­ã¿è¾¼ã¿
    with open(input_path, 'r', newline='', encoding='utf-8-sig') as f:
        reader = csv.DictReader(f)
        rows = list(reader)
    
    # åˆ†å‰²ã—ã¦å‡ºåŠ›
    total_files = 0
    for i in range(0, len(rows), posts_per_file):
        chunk = rows[i:i + posts_per_file]
        file_num = (i // posts_per_file) + 1
        output_file = output_dir / f"{week_label}_part{file_num:03d}.csv"
        
        with open(output_file, 'w', newline='', encoding='utf-8-sig') as f:
            writer = csv.DictWriter(
                f,
                fieldnames=["Text", "Image URL", "Tags", "Posting Time"],
                quoting=csv.QUOTE_ALL
            )
            writer.writeheader()
            writer.writerows(chunk)
        
        total_files += 1
        print(f"âœ… {output_file.name}: {len(chunk)}æŠ•ç¨¿")
    
    return total_files


if __name__ == "__main__":
    outputs_dir = Path(__file__).parent / "outputs"
    buffer_files = list(outputs_dir.glob("*_buffer_import.csv"))
    
    total_parts = 0
    for buffer_file in sorted(buffer_files):
        print(f"\nğŸ“‚ {buffer_file.name} ã‚’åˆ†å‰²ä¸­...")
        parts = split_buffer_csv(buffer_file, posts_per_file=10)
        total_parts += parts
    
    print(f"\nğŸ‰ åˆè¨ˆ {total_parts} ãƒ•ã‚¡ã‚¤ãƒ«ã«åˆ†å‰²å®Œäº†")
    print(f"ğŸ“ å‡ºåŠ›å…ˆ: {outputs_dir / 'buffer_split'}")
