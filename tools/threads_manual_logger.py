#!/usr/bin/env python3
"""
Threads Manual Performance Logger - æ‰‹å‹•ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è¨˜éŒ²ãƒ„ãƒ¼ãƒ«

Threads APIãŒæœªè¨­å®šã®å ´åˆã§ã‚‚ã€ã‚¢ãƒ—ãƒªã§ç¢ºèªã—ãŸ
ã€Œã„ã„ã­ã€ã€Œé–²è¦§æ•°ã€ã‚’æ‰‹å‹•ã§è¨˜éŒ²ã—ã€å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã™ã‚‹ã€‚

Usage:
    # å¯¾è©±ãƒ¢ãƒ¼ãƒ‰ã§è¨˜éŒ²
    python threads_manual_logger.py

    # è¨˜éŒ²ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
    python threads_manual_logger.py --report

    # CSVä¸€æ‹¬ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
    python threads_manual_logger.py --import performance.csv
"""

import argparse
import csv
import json
import os
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional

import pandas as pd

# Configuration paths
BASE_DIR = Path(__file__).parent.parent
TOOLS_DIR = Path(__file__).parent
LEARNING_DIR = BASE_DIR / "learning"
LOG_FILE = LEARNING_DIR / "threads_performance_log.json"
SCHEDULE_FILE = BASE_DIR / "research_ideas" / "relationship" / "600_posts_schedule.csv"


def ensure_dirs():
    """å¿…è¦ãªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ"""
    LEARNING_DIR.mkdir(parents=True, exist_ok=True)


def load_log() -> List[Dict]:
    """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ­ã‚°ã‚’èª­ã¿è¾¼ã¿"""
    if LOG_FILE.exists():
        with open(LOG_FILE, "r", encoding="utf-8") as f:
            return json.load(f)
    return []


def save_log(data: List[Dict]):
    """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ­ã‚°ã‚’ä¿å­˜"""
    ensure_dirs()
    with open(LOG_FILE, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)
    print(f"âœ… ãƒ­ã‚°ä¿å­˜: {LOG_FILE}")


def load_schedule() -> pd.DataFrame:
    """æŠ•ç¨¿ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’èª­ã¿è¾¼ã¿"""
    if SCHEDULE_FILE.exists():
        return pd.read_csv(SCHEDULE_FILE)
    return pd.DataFrame()


def interactive_log():
    """å¯¾è©±ãƒ¢ãƒ¼ãƒ‰ã§ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’è¨˜éŒ²"""
    print(
        """
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘            Threads æ‰‹å‹•ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è¨˜éŒ²                                      â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Threadsã‚¢ãƒ—ãƒªã§ç¢ºèªã—ãŸæŠ•ç¨¿ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’è¨˜éŒ²ã—ã¾ã™ã€‚
çµ‚äº†ã™ã‚‹ã«ã¯ 'q' ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚
"""
    )

    schedule = load_schedule()
    log = load_log()

    while True:
        print("\n" + "-" * 40)

        # Dayç•ªå·å…¥åŠ›
        day_input = input("ğŸ“… Dayç•ªå· (ä¾‹: 1-21, q=çµ‚äº†): ").strip()
        if day_input.lower() == "q":
            break

        try:
            day = int(day_input)
        except ValueError:
            print("âŒ æ•°å­—ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
            continue

        # Noç•ªå·å…¥åŠ›
        no_input = input("ğŸ“ æŠ•ç¨¿No (ä¾‹: 1-10): ").strip()
        try:
            no = int(no_input)
        except ValueError:
            print("âŒ æ•°å­—ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
            continue

        # ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã‹ã‚‰æŠ•ç¨¿å†…å®¹ã‚’å–å¾—ã—ã¦è¡¨ç¤º
        if not schedule.empty:
            post = schedule[(schedule["Day"] == day) & (schedule["No"] == no)]
            if not post.empty:
                content = post.iloc[0]["Content"]
                post_type = post.iloc[0]["Type"]
                time = post.iloc[0]["Time"]
                print(f"\nã€æŠ•ç¨¿å†…å®¹ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã€‘")
                print(f"  ã‚¿ã‚¤ãƒ—: {post_type}")
                print(f"  æ™‚é–“: {time}")
                print(f"  å†…å®¹: {content[:100]}...")
            else:
                print(f"âš ï¸ Day{day}_No{no} ãŒã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã«è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")

        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å…¥åŠ›
        views_input = input("ğŸ‘ï¸ é–²è¦§æ•°: ").strip()
        likes_input = input("â¤ï¸ ã„ã„ã­æ•°: ").strip()
        replies_input = input("ğŸ’¬ è¿”ä¿¡æ•° (çœç•¥å¯): ").strip() or "0"
        reposts_input = input("ğŸ”„ ãƒªãƒã‚¹ãƒˆæ•° (çœç•¥å¯): ").strip() or "0"

        try:
            views = int(views_input)
            likes = int(likes_input)
            replies = int(replies_input)
            reposts = int(reposts_input)
        except ValueError:
            print("âŒ æ•°å­—ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
            continue

        # ãƒ¡ãƒ¢ï¼ˆä»»æ„ï¼‰
        note = input("ğŸ“ ãƒ¡ãƒ¢ (ä»»æ„): ").strip()

        # è¨˜éŒ²è¿½åŠ 
        record = {
            "day": day,
            "no": no,
            "post_id": f"Day{day}_No{no}",
            "views": views,
            "likes": likes,
            "replies": replies,
            "reposts": reposts,
            "engagement_total": likes + replies + reposts,
            "engagement_rate": round((likes + replies + reposts) / (views + 1) * 100, 2),
            "note": note,
            "recorded_at": datetime.now().isoformat(),
        }

        # æŠ•ç¨¿å†…å®¹ã‚‚ä¿å­˜
        if not schedule.empty and not post.empty:
            record["content"] = post.iloc[0]["Content"]
            record["type"] = post.iloc[0]["Type"]
            record["time"] = post.iloc[0]["Time"]

        # æ—¢å­˜ãƒ¬ã‚³ãƒ¼ãƒ‰ã‚’ãƒã‚§ãƒƒã‚¯ï¼ˆåŒã˜post_idãªã‚‰æ›´æ–°ï¼‰
        existing_idx = next(
            (i for i, r in enumerate(log) if r["post_id"] == record["post_id"]), None
        )
        if existing_idx is not None:
            log[existing_idx] = record
            print(f"ğŸ”„ Day{day}_No{no} ã‚’æ›´æ–°ã—ã¾ã—ãŸ")
        else:
            log.append(record)
            print(f"âœ… Day{day}_No{no} ã‚’è¨˜éŒ²ã—ã¾ã—ãŸ")

        save_log(log)

    print("\nâœ… è¨˜éŒ²ã‚’çµ‚äº†ã—ã¾ã—ãŸ")


def generate_report():
    """è¨˜éŒ²ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ"""
    log = load_log()

    if not log:
        print("âŒ è¨˜éŒ²ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚ã¾ãšå¯¾è©±ãƒ¢ãƒ¼ãƒ‰ã§è¨˜éŒ²ã—ã¦ãã ã•ã„ã€‚")
        return

    df = pd.DataFrame(log)

    print(
        """
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘            Threads ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¬ãƒãƒ¼ãƒˆ                                      â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""
    )

    # å…¨ä½“çµ±è¨ˆ
    print("ã€ğŸ“Š å…¨ä½“çµ±è¨ˆã€‘")
    print(f"  è¨˜éŒ²æŠ•ç¨¿æ•°: {len(df)}ä»¶")
    print(f"  ç·é–²è¦§æ•°: {df['views'].sum():,}")
    print(f"  ç·ã„ã„ã­æ•°: {df['likes'].sum():,}")
    print(f"  å¹³å‡é–²è¦§æ•°: {df['views'].mean():.1f}")
    print(f"  å¹³å‡ã„ã„ã­æ•°: {df['likes'].mean():.1f}")
    print(f"  å¹³å‡ER: {df['engagement_rate'].mean():.2f}%")

    # 100é–²è¦§ä»¥ä¸Š
    high_views = df[df["views"] >= 100]
    print(f"\nã€ğŸ”¥ 100é–²è¦§ä»¥ä¸Šã®æŠ•ç¨¿ã€‘ {len(high_views)}ä»¶")
    for _, row in high_views.sort_values("views", ascending=False).iterrows():
        print(f"  {row['post_id']}: ğŸ‘ï¸{row['views']} â¤ï¸{row['likes']} - {row.get('type', 'N/A')}")

    # ã„ã„ã­ç²å¾—æŠ•ç¨¿
    liked = df[df["likes"] >= 1]
    print(f"\nã€â¤ï¸ ã„ã„ã­ç²å¾—æŠ•ç¨¿ã€‘ {len(liked)}ä»¶")
    for _, row in liked.sort_values("likes", ascending=False).iterrows():
        print(f"  {row['post_id']}: ğŸ‘ï¸{row['views']} â¤ï¸{row['likes']} - {row.get('type', 'N/A')}")

    # ã‚¿ã‚¤ãƒ—åˆ¥åˆ†æ
    if "type" in df.columns:
        print(f"\nã€ğŸ“ ã‚¿ã‚¤ãƒ—åˆ¥ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã€‘")
        type_stats = df.groupby("type").agg(
            {
                "views": "mean",
                "likes": "mean",
                "engagement_rate": "mean",
                "post_id": "count",
            }
        ).round(2)
        type_stats.columns = ["å¹³å‡é–²è¦§", "å¹³å‡ã„ã„ã­", "å¹³å‡ER%", "æŠ•ç¨¿æ•°"]
        type_stats = type_stats.sort_values("å¹³å‡ER%", ascending=False)
        print(type_stats.to_string())

    # æ™‚é–“å¸¯åˆ¥åˆ†æ
    if "time" in df.columns:
        print(f"\nã€â° æ™‚é–“å¸¯åˆ¥ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã€‘")
        time_stats = df.groupby("time").agg(
            {
                "views": "mean",
                "likes": "mean",
                "engagement_rate": "mean",
                "post_id": "count",
            }
        ).round(2)
        time_stats.columns = ["å¹³å‡é–²è¦§", "å¹³å‡ã„ã„ã­", "å¹³å‡ER%", "æŠ•ç¨¿æ•°"]
        time_stats = time_stats.sort_values("å¹³å‡ER%", ascending=False)
        print(time_stats.to_string())

    # å­¦ç¿’ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ
    generate_learning_prompt(df)


def generate_learning_prompt(df: pd.DataFrame):
    """å­¦ç¿’ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆã—ã¦ä¿å­˜"""
    ensure_dirs()

    # é«˜ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æŠ•ç¨¿ã‚’æŠ½å‡º
    high_perform = df[(df["views"] >= 100) | (df["likes"] >= 1)].copy()

    if high_perform.empty:
        high_perform = df.nlargest(5, "engagement_rate")

    # ã‚µãƒ³ãƒ—ãƒ«æŠ•ç¨¿
    samples = []
    for _, row in high_perform.sort_values("engagement_rate", ascending=False).head(5).iterrows():
        content = row.get("content", "ï¼ˆå†…å®¹æœªè¨˜éŒ²ï¼‰")
        samples.append(
            f"""ã€{row['post_id']} - ğŸ‘ï¸{row['views']} â¤ï¸{row['likes']} ER:{row['engagement_rate']:.2f}%ã€‘
ã‚¿ã‚¤ãƒ—: {row.get('type', 'N/A')}
æ™‚é–“: {row.get('time', 'N/A')}
å†…å®¹:
{content[:300]}...
"""
        )

    # ã‚¿ã‚¤ãƒ—åˆ¥ãƒ™ã‚¹ãƒˆ
    type_best = ""
    if "type" in df.columns:
        type_stats = df.groupby("type")["engagement_rate"].mean().sort_values(ascending=False)
        type_best = "\n".join([f"  {i+1}. {t}: {er:.2f}%" for i, (t, er) in enumerate(type_stats.head(3).items())])

    # æ™‚é–“å¸¯åˆ¥ãƒ™ã‚¹ãƒˆ
    time_best = ""
    if "time" in df.columns:
        time_stats = df.groupby("time")["engagement_rate"].mean().sort_values(ascending=False)
        time_best = "\n".join([f"  {i+1}. {t}: {er:.2f}%" for i, (t, er) in enumerate(time_stats.head(3).items())])

    prompt = f"""# ãƒ¬ã‚¹å’å…ˆè¼© 21daysæŠ•ç¨¿ å­¦ç¿’ãƒ‡ãƒ¼ã‚¿
ç”Ÿæˆæ—¥æ™‚: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

## ğŸ“Š åˆ†ææœŸé–“ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹
- åˆ†ææŠ•ç¨¿æ•°: {len(df)}ä»¶
- 100é–²è¦§ä»¥ä¸Š: {len(df[df['views'] >= 100])}ä»¶
- ã„ã„ã­ç²å¾—: {len(df[df['likes'] >= 1])}ä»¶
- å¹³å‡é–²è¦§æ•°: {df['views'].mean():.1f}
- å¹³å‡ã„ã„ã­æ•°: {df['likes'].mean():.1f}
- å¹³å‡ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆç‡: {df['engagement_rate'].mean():.2f}%

## ğŸ¯ åŠ¹æœçš„ãªæŠ•ç¨¿ã‚¿ã‚¤ãƒ—
{type_best if type_best else "ï¼ˆãƒ‡ãƒ¼ã‚¿ä¸è¶³ï¼‰"}

## â° åŠ¹æœçš„ãªæŠ•ç¨¿æ™‚é–“
{time_best if time_best else "ï¼ˆãƒ‡ãƒ¼ã‚¿ä¸è¶³ï¼‰"}

## âœ¨ é«˜ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æŠ•ç¨¿ã‚µãƒ³ãƒ—ãƒ«

{"".join(samples)}

## ğŸ’¡ 22æ—¥ç›®ä»¥é™ã®æŠ•ç¨¿æ”¹å–„æŒ‡é‡

ä¸Šè¨˜ã®é«˜ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æŠ•ç¨¿ã‚’åˆ†æã—ãŸçµæœã€ä»¥ä¸‹ã®è¦ç´ ãŒåŠ¹æœçš„ã¨æ¨æ¸¬ã•ã‚Œã¾ã™ï¼š

1. **å…±æ„Ÿã‚’èª˜ã†å…·ä½“çš„ã‚·ãƒ¼ãƒ³æå†™**
   - ã€Œã€œã‚ã‚Šã¾ã›ã‚“ã‹ï¼Ÿã€ã¨ã„ã†å•ã„ã‹ã‘å½¢å¼
   - æ—¥å¸¸ã®ã€Œã‚ã‚‹ã‚ã‚‹ã€ã‚’è¨€èªåŒ–

2. **é©åˆ‡ãªæ–‡å­—æ•°ã¨æ§‹æˆ**
   - æ”¹è¡Œã‚’åŠ¹æœçš„ã«ä½¿ç”¨
   - èª­ã¿ã‚„ã™ã„ãƒªã‚ºãƒ 

3. **æŠ•ç¨¿æ™‚é–“ã®æœ€é©åŒ–**
   - æœï¼ˆ7-8æ™‚ï¼‰ï¼š1æ—¥ã®å§‹ã¾ã‚Šã«å…±æ„Ÿ
   - æ˜¼ï¼ˆ12æ™‚ï¼‰ï¼šæ˜¼ä¼‘ã¿ã®ã‚¹ãƒãƒ›ã‚¿ã‚¤ãƒ 
   - å¤•æ–¹-å¤œï¼ˆ17-21æ™‚ï¼‰ï¼šå¸°å®…å¾Œã®ãƒªãƒ©ãƒƒã‚¯ã‚¹ã‚¿ã‚¤ãƒ 

4. **ã‚¿ã‚¤ãƒ—ã®ä½¿ã„åˆ†ã‘**
   - æœ¬æ°—(å…±æ„Ÿ): æ·±ã„å…±æ„Ÿã‚’èª˜ã†é•·æ–‡
   - è»½ã‚(å•): è€ƒãˆã•ã›ã‚‹è³ªå•å½¢å¼
   - è»½ã‚(ä¸€è¨€): ã‚µã‚¯ãƒƒã¨èª­ã‚ã‚‹ä¸€è¨€

---
ã“ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½¿ç”¨ã—ã¦ã€22æ—¥ç›®ä»¥é™ã®æŠ•ç¨¿ã‚’ç”Ÿæˆãƒ»æ”¹å–„ã—ã¦ãã ã•ã„ã€‚
"""

    # ä¿å­˜
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    prompt_file = LEARNING_DIR / f"threads_learning_manual_{timestamp}.md"
    with open(prompt_file, "w", encoding="utf-8") as f:
        f.write(prompt)
    print(f"\nâœ… å­¦ç¿’ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä¿å­˜: {prompt_file}")

    # JSONã‚‚ä¿å­˜
    data = {
        "generated_at": datetime.now().isoformat(),
        "total_posts": len(df),
        "avg_views": round(df["views"].mean(), 2),
        "avg_likes": round(df["likes"].mean(), 2),
        "avg_er": round(df["engagement_rate"].mean(), 2),
        "high_perform_posts": high_perform.to_dict("records"),
    }
    data_file = LEARNING_DIR / f"threads_learning_manual_{timestamp}.json"
    with open(data_file, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)
    print(f"âœ… å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ä¿å­˜: {data_file}")


def import_csv(csv_path: str):
    """CSVã‹ã‚‰ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ"""
    if not os.path.exists(csv_path):
        print(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {csv_path}")
        return

    print(f"ğŸ“¥ CSVã‚¤ãƒ³ãƒãƒ¼ãƒˆ: {csv_path}")

    df = pd.read_csv(csv_path)
    required_cols = ["day", "no", "views", "likes"]

    for col in required_cols:
        if col not in df.columns:
            print(f"âŒ å¿…é ˆã‚«ãƒ©ãƒ  '{col}' ãŒã‚ã‚Šã¾ã›ã‚“")
            print(f"   å¿…é ˆ: {required_cols}")
            return

    log = load_log()
    schedule = load_schedule()

    imported = 0
    for _, row in df.iterrows():
        day = int(row["day"])
        no = int(row["no"])
        post_id = f"Day{day}_No{no}"

        record = {
            "day": day,
            "no": no,
            "post_id": post_id,
            "views": int(row["views"]),
            "likes": int(row["likes"]),
            "replies": int(row.get("replies", 0)),
            "reposts": int(row.get("reposts", 0)),
            "recorded_at": datetime.now().isoformat(),
        }

        record["engagement_total"] = (
            record["likes"] + record["replies"] + record["reposts"]
        )
        record["engagement_rate"] = round(
            record["engagement_total"] / (record["views"] + 1) * 100, 2
        )

        # ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã‹ã‚‰æŠ•ç¨¿å†…å®¹ã‚’å–å¾—
        if not schedule.empty:
            post = schedule[(schedule["Day"] == day) & (schedule["No"] == no)]
            if not post.empty:
                record["content"] = post.iloc[0]["Content"]
                record["type"] = post.iloc[0]["Type"]
                record["time"] = post.iloc[0]["Time"]

        # æ—¢å­˜ãƒã‚§ãƒƒã‚¯
        existing_idx = next(
            (i for i, r in enumerate(log) if r["post_id"] == post_id), None
        )
        if existing_idx is not None:
            log[existing_idx] = record
        else:
            log.append(record)

        imported += 1

    save_log(log)
    print(f"âœ… {imported}ä»¶ã‚¤ãƒ³ãƒãƒ¼ãƒˆå®Œäº†")


def main():
    parser = argparse.ArgumentParser(
        description="Threads Manual Performance Logger"
    )
    parser.add_argument(
        "--report", action="store_true", help="è¨˜éŒ²ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"
    )
    parser.add_argument("--import", dest="import_csv", help="CSVã‹ã‚‰ã‚¤ãƒ³ãƒãƒ¼ãƒˆ")

    args = parser.parse_args()

    if args.report:
        generate_report()
    elif args.import_csv:
        import_csv(args.import_csv)
    else:
        interactive_log()


if __name__ == "__main__":
    main()
